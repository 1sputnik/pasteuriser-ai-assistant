***<h1 align = "center">Pasteuriser AI Assistant</a>***

# **Прогнозирование временных рядов с помощью LSTM**

## **Цель работы:**

<p align = "justify">
Спрогнозировать поведение графика, моделью, написанной на С++.
</p>

## **Поиск и выбор средств прогнозирования:**

<p align = "justify">
В ходе изучения задачи и дальнейшего поиска её решения были рассмотрены такие средства прогнозирования как ARMA, ARIMA, деревья решений, множественная регрессия, однако остановились на нейросетевом способе, а именно на рекуррентных нейронных сетях. В качестве модели прогнозирования была выбрана модель LSTM. Был изучен её математический аппарат, а также метод обратного распространения во времени для обучения LSTM.
</p>

## **Математическая модель LSTM:**

<p align = "justify">
Предсказание LSTM основывается на предыдущих результатах. Поэтому LSTM для предсказания можно отобразить следующим образом: 
</p>

![](images/forc.jpg)  

<p align = "justify">
На картинке представлена LSTM относительно её блоков. На вход она принимает некоторые значения Xt и свою память Ht-1 и Ct-1 и выдаёт Ht для дальнейшего расчёта предсказания. Ниже на картинке будет представлена нейронная схема блока LSTM:
</p>

![](images/lstm_math_model.png)  

<p align = "justify">
В качестве входных данных выступают xt, ht-1 и Ct-1. Что есть что? xt - вектор входных значений, представляющий цепочку реальных данных. ht-1 - вектор передающийся из прошлой итерации сети, представляющий краткосрочную память сети. ht-1 - вектор передающийся из прошлой итерации сети, представляющий долгосрочную память сети. Сеть, имея долгосрочную и краткосрочную память, поэтому и называется Long short-term memory.
</p>

<p align = "justify">
Ft - это один из так называемых вентилей и врат сети, представляющий вектор забывания. Его смысл в том, что он указщывает на то, что необходимо как бы забыть из долгосрочной памяти.
</p>

![](images/F.png)  

<p align = "justify">
It и Gt - это вентили сети, представляющий вектор новых состояний долгосрочной памяти. Смысл Gt заключается в том, что он сосдаёт новых претиндентов на место новой долгосрочной памяти, а It уже будет решать, что из Gt попадёт в настоящую долгосрочную память.
</p>

![](images/IG.png)  

<p align = "justify">
Ot - это вентиль сети, представляющий вектор выходных значений долгосрочной памяти для расчёта новой краткосрочной. Смысл Ot заключается в том, что он говорит, какая часть из долгосрочной памяти нам необходима, чтобы выполнить предсказание на основе расчёта краткосрочной. 
</p>

![](images/O.png)  

<p align = "justify">
Далее рассчитываем долгосрочную и краткосрочную память.
</p>

![](images/Ch.png)  

<p align = "justify">
После чего приступаем к расчёту прогноза.
</p>

![](images/y.png)  

## **Метод обратного распространения во времени:**  

<p align = "justify">
Сеть обучается по методу обратного распространения во времени. ПОяснения по формулам давать незачем, поэтому только выведим их, т.к. из цель найти распространения ошибки по весам для их изменения по backpropagation.
</p>

<p align = "justify">
Рассчитаем ошибку по предсказанию и обучим веса предсказания: 
</p>

![](images/dedy.jpg)  

<p align = "justify">
Рассчитаем ошибку по памяти сети: 
</p>

![](images/dedmemory.jpg)  

<p align = "justify">
Рассчитаем ошибку по выходным вратам и обучим выходным веса: 
</p>

![](images/dedO.jpg)  

<p align = "justify">
Рассчитаем ошибку по входным вратам и обучим входные веса: 
</p>

![](images/dedI.jpg)  

<p align = "justify">
Рассчитаем ошибку по вратам состояний и обучим веса состояний: 
</p>

![](images/dedG.jpg)  

<p align = "justify">
Рассчитаем ошибку по вратам забывания и обучим веса забывания: 
</p>

![](images/dedF.jpg)  


## **Результаты работы программы:**  

<p align = "justify">
Красная линия - обучающая выборка, синяя линия - реальные данные, зелёная линия - предсказания сети. Результаты по data 1 cid 6:
</p>

![](images/1.png)  

![](images/2.png)  

![](images/3.png)  
